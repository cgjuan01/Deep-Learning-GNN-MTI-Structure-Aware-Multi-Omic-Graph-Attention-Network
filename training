#!/usr/bin/env python3
import argparse
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GATConv
from torch_geometric.data import Data

# ---------------------------------------------------------
# 1. Model definition
# ---------------------------------------------------------
class GATEncoder(nn.Module):
    def __init__(self, in_dim, hidden_dim=64, out_dim=64, heads=4, dropout=0.2):
        super().__init__()
        self.gat1 = GATConv(in_dim, hidden_dim, heads=heads, dropout=dropout)
        self.gat2 = GATConv(hidden_dim * heads, out_dim, heads=1, dropout=dropout)
        self.dropout = dropout

    def forward(self, x, edge_index):
        x = self.gat1(x, edge_index)
        x = F.elu(x)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.gat2(x, edge_index)
        return x


class MTIMultiNet(nn.Module):
    def __init__(self, in_dim, hidden_dim=64, out_dim=64, heads=4, dropout=0.2):
        super().__init__()
        self.encoder = GATEncoder(in_dim, hidden_dim, out_dim, heads, dropout)
        self.reg_head = nn.Linear(out_dim, 1)  # MTI regression
        self.cls_head = nn.Linear(out_dim, 1)  # multi-layer classification

    def forward(self, x, edge_index):
        h = self.encoder(x, edge_index)
        mti_pred = self.reg_head(h).squeeze(-1)
        multi_logit = self.cls_head(h).squeeze(-1)
        return mti_pred, multi_logit


# ---------------------------------------------------------
# 2. Utility: build edge index from from/to gene symbols
# ---------------------------------------------------------
def build_edge_index(edge_df, gene_to_idx):
    # Expect columns "from" and "to"
    if not {"from", "to"}.issubset(edge_df.columns):
        raise ValueError("Edge file must have 'from' and 'to' columns with gene symbols.")

    src = edge_df["from"].map(gene_to_idx).to_numpy()
    dst = edge_df["to"].map(gene_to_idx).to_numpy()

    mask = ~pd.isna(src) & ~pd.isna(dst)
    src = src[mask].astype(np.int64)
    dst = dst[mask].astype(np.int64)

    edge_index = torch.tensor(
        np.vstack([src, dst]),
        dtype=torch.long
    )
    return edge_index


# ---------------------------------------------------------
# 3. Main
# ---------------------------------------------------------
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--node_path", required=True,
                        help="Path to GNN node table (MR + sc-MR + struct + RE-PANTHER).")
    parser.add_argument("--edge_path", required=True,
                        help="Path to kNN edge table (k=15).")
    parser.add_argument("--out_path", default=None,
                        help="Output TSV for embeddings + ranks "
                             "(default: same folder with *_GNN_MULTI.tsv).")
    parser.add_argument("--epochs", type=int, default=300)
    parser.add_argument("--lr", type=float, default=1e-3)
    parser.add_argument("--lambda_multi", type=float, default=0.3)
    args = parser.parse_args()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}\n")

    # -----------------------------------------
    # 3.1 Load node table
    # -----------------------------------------
    print(f"üìÇ Loading node table:\n    {args.node_path}")
    node_df = pd.read_csv(args.node_path, sep="\t")
    print(f"Node rows: {len(node_df)}  Cols: {len(node_df.columns)}")

    if "gene_symbol" not in node_df.columns:
        raise ValueError("gene_symbol column missing in node table.")
    if "MTI_score" not in node_df.columns:
        raise ValueError("MTI_score column missing in node table.")

    # Features: all numeric except MTI targets
    numeric_cols = node_df.select_dtypes(include=[np.number]).columns.tolist()
    drop_targets = [c for c in ["MTI_score", "MTI_sumsq", "MTI_n_layers"] if c in numeric_cols]
    feature_cols = [c for c in numeric_cols if c not in drop_targets]

    print("\nUsing feature columns for GNN (first 15):")
    print("   ", feature_cols[:15], "...")
    print("Total feature dims:", len(feature_cols))

    X = node_df[feature_cols].to_numpy(dtype=np.float32)

    # Targets
    mti = node_df["MTI_score"].to_numpy(dtype=np.float32)
    mti_mask = np.isfinite(mti)

    # Multi-layer labels, if present
    has_multi = "MTI_n_layers" in node_df.columns
    multi_labels = None
    pos_weight = None

    if has_multi:
        n_layers = node_df["MTI_n_layers"].to_numpy()
        multi_labels = (n_layers >= 2).astype(np.float32)
        n_pos = float(multi_labels.sum())
        n_tot = float(len(multi_labels))
        n_neg = n_tot - n_pos
        print(f"\nMulti-layer positives (MTI_n_layers >= 2): {int(n_pos)} / {int(n_tot)}")

        if n_pos > 0 and n_neg > 0:
            raw_pw = n_neg / n_pos
            capped_pw = min(raw_pw, 50.0)  # avoid extreme instability
            pos_weight = torch.tensor(capped_pw, dtype=torch.float32, device=device)
            print(f"Using pos_weight for BCE: raw={raw_pw:.2f}, capped={capped_pw:.2f}")
        else:
            print("‚ö† No positive multi-layer examples. Disabling multi-layer loss.")
            has_multi = False

    # Standardise features (per-column)
    mean = np.nanmean(X, axis=0)
    std = np.nanstd(X, axis=0)
    std[std == 0] = 1.0
    X = (X - mean) / std
    X[~np.isfinite(X)] = 0.0

    x = torch.tensor(X, dtype=torch.float32, device=device)
    y_mti = torch.tensor(mti, dtype=torch.float32, device=device)
    mti_mask_t = torch.tensor(mti_mask, dtype=torch.bool, device=device)

    if has_multi:
        y_multi = torch.tensor(multi_labels, dtype=torch.float32, device=device)
        bce = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
    else:
        y_multi = None
        bce = None

    # -----------------------------------------
    # 3.2 Load edges and build edge_index
    # -----------------------------------------
    print(f"\nüìÇ Loading edge table:\n    {args.edge_path}")
    edge_df = pd.read_csv(args.edge_path, sep="\t")

    # Detect columns
    if not {"from", "to"}.issubset(edge_df.columns):
        # Try to infer
        candidates_from = [c for c in edge_df.columns if c.lower() in ("from", "source", "gene1")]
        candidates_to   = [c for c in edge_df.columns if c.lower() in ("to", "target", "gene2")]
        if not candidates_from or not candidates_to:
            raise ValueError("Could not detect 'from'/'to' columns in edge file.")
        edge_df = edge_df.rename(columns={
            candidates_from[0]: "from",
            candidates_to[0]:   "to"
        })

    print("Edge rows:", len(edge_df))
    gene_symbols = node_df["gene_symbol"].tolist()
    gene_to_idx = {g: i for i, g in enumerate(gene_symbols)}

    edge_index = build_edge_index(edge_df, gene_to_idx)
    print(f"Edge index shape: {edge_index.shape}")
    print(
        f"Edge index value range: src [{edge_index[0].min().item()}..{edge_index[0].max().item()}], "
        f"dst [{edge_index[1].min().item()}..{edge_index[1].max().item()}]"
    )

    data = Data(x=x, edge_index=edge_index)
    data = data.to(device)

    # -----------------------------------------
    # 3.3 Model + training
    # -----------------------------------------
    model = MTIMultiNet(in_dim=len(feature_cols), hidden_dim=64, out_dim=64,
                        heads=4, dropout=0.2).to(device)
    optim = torch.optim.Adam(model.parameters(), lr=args.lr)

    print("\nStarting training‚Ä¶\n")
    lambda_multi = args.lambda_multi if has_multi else 0.0
    print(f"lambda_multi = {lambda_multi}\n")

    for epoch in range(1, args.epochs + 1):
        model.train()
        optim.zero_grad()

        mti_pred, multi_logit = model(data.x, data.edge_index)

        # MTI regression loss
        mti_loss = F.mse_loss(mti_pred[mti_mask_t], y_mti[mti_mask_t])

        if has_multi and lambda_multi > 0.0:
            multi_loss = bce(multi_logit, y_multi)
            loss = mti_loss + lambda_multi * multi_loss
        else:
            multi_loss = torch.tensor(0.0, device=device)
            loss = mti_loss

        if torch.isnan(loss):
            print(f"Epoch {epoch:03d} | ‚ùå NaN loss, stopping.")
            break

        loss.backward()
        optim.step()

        if epoch == 1 or epoch % 20 == 0 or epoch == args.epochs:
            print(
                f"Epoch {epoch:03d} | "
                f"MTI MSE: {mti_loss.item():.4f} | "
                f"Multi BCE: {multi_loss.item():.4f} | "
                f"Total: {loss.item():.4f}"
            )

    print("\n‚úÖ Training complete.\n")

    # -----------------------------------------
    # 3.4 Save embeddings + ranks
    # -----------------------------------------
    model.eval()
    with torch.no_grad():
        mti_pred, multi_logit = model(data.x, data.edge_index)
        multi_prob = torch.sigmoid(multi_logit)

    mti_pred_np = mti_pred.cpu().numpy()
    multi_prob_np = multi_prob.cpu().numpy()

    # Ranks: higher MTI_pred = better (rank 1)
    order = np.argsort(-mti_pred_np)
    ranks = np.empty_like(order)
    ranks[order] = np.arange(1, len(order) + 1)

    rank_scaled = (len(ranks) - ranks) / (len(ranks) - 1.0)

    out_df = node_df[["gene_symbol"]].copy()
    out_df["MTI_score"] = mti
    out_df["GNN_EXERCISE_SUP_MTI_MULTI_pred"] = mti_pred_np
    out_df["GNN_EXERCISE_SUP_MTI_MULTI_rank"] = ranks.astype(int)
    out_df["GNN_EXERCISE_SUP_MTI_MULTI_rank_scaled"] = rank_scaled
    out_df["GNN_EXERCISE_SUP_MTI_MULTI_multi_prob"] = multi_prob_np

    # Decide output path
    if args.out_path is None:
        base = args.node_path.rsplit("/", 1)[-1].replace(".tsv", "")
        out_path = (
            "/Users/ciara/Downloads/LDaware_MR_proteins/"
            f"GNN_embeddings_EXERCISEONLY_GAT_SUP_MTI_MULTI_MR_SC_STRUCT_PANTHER_REPANTHER.tsv"
        )
    else:
        out_path = args.out_path

    out_df.to_csv(out_path, sep="\t", index=False)
    print(f"Saved hybrid MTI‚ÄìGNN embeddings + ranks to:\n   {out_path}\n")

    # Print key genes
    key_genes = ["B4GALT1", "ST6GAL1", "MGAT3", "FUT8", "FUT6", "SIRT1", "SIRT6"]
    print("Key genes (hybrid MTI + multi-layer objective):")
    print(
        out_df[out_df["gene_symbol"].isin(key_genes)][
            [
                "gene_symbol",
                "MTI_score",
                "GNN_EXERCISE_SUP_MTI_MULTI_pred",
                "GNN_EXERCISE_SUP_MTI_MULTI_rank",
                "GNN_EXERCISE_SUP_MTI_MULTI_rank_scaled",
                "GNN_EXERCISE_SUP_MTI_MULTI_multi_prob",
            ]
        ]
    )


if __name__ == "__main__":
    main()


